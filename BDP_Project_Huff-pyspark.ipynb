{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0-cdh6.3.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "import sh\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "datetime.now()\n",
    "import matplotlib.pyplot as plt\n",
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/user/ivy2/Tweets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !hadoop fs -ls /user/ivy2/Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_all = spark.read.json(path).withColumn('coal_text',F.lower(F.coalesce(F.col('extended_tweet.full_text'), F.col('text')))) \\\n",
    "                                    .withColumn('uchicago', F.when((F.col('coal_text').contains('university of chicago')) |\n",
    "                                                                   (F.col('coal_text').contains('universityofchicago')) |\n",
    "                                                                   (F.col('coal_text').contains('uchicago')) |\n",
    "                                                                   (F.col('coal_text').contains('uofc')), 'uchicago')) \\\n",
    "                                    .withColumn('cornell', F.when(F.col('coal_text').contains('cornell'), 'cornell')) \\\n",
    "                                    .withColumn('stanford', F.when(F.col('coal_text').contains('stanford'), 'stanford')) \\\n",
    "                                    .withColumn('cm', F.when((F.col('coal_text').contains('carnegiemellon')) |\n",
    "                                                             (F.col('coal_text').contains('carnegie mellon')), 'cm')) \\\n",
    "                                    .withColumn('school', F.coalesce('uchicago', 'cornell', 'stanford', 'cm')) \\\n",
    "                                    .drop('uchicago') \\\n",
    "                                    .drop('cornell') \\\n",
    "                                    .drop('cm') \\\n",
    "                                    .drop('stanford')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_uni = tweets_all.filter(~F.col('school').isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>school</th><th>count</th></tr>\n",
       "<tr><td>uchicago</td><td>800086</td></tr>\n",
       "<tr><td>stanford</td><td>1794758</td></tr>\n",
       "<tr><td>rutgers</td><td>321657</td></tr>\n",
       "<tr><td>cornell</td><td>360399</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-------+\n",
       "|  school|  count|\n",
       "+--------+-------+\n",
       "|uchicago| 800086|\n",
       "|stanford|1794758|\n",
       "| rutgers| 321657|\n",
       "| cornell| 360399|\n",
       "+--------+-------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_uni.groupBy('school').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_uni = tweets_uni.filter(F.col('lang')=='en') \\\n",
    "                        .select([F.col('id').alias('tweet_id'),\n",
    "                                 F.col('created_at').alias('tweet_dt'),\n",
    "                                 F.col('source'),\n",
    "                                 F.col('school'),\n",
    "                                 F.col('in_reply_to_user_id').alias('is_reply'), \n",
    "                                 F.col('quoted_status'),\n",
    "                                 F.col('retweeted_status'),\n",
    "                                 F.col('entities.media.type').alias('media_type'),\n",
    "                                 F.col('entities.user_mentions.id').alias('user_mentions_id'),\n",
    "                                 F.col('favorite_count'),\n",
    "                                 F.col('retweet_count'),\n",
    "                                 F.col('user.created_at').alias('user_created_at'), \n",
    "                                 F.col('user.favourites_count').alias('user_favorites_count'),\n",
    "                                 F.col('user.followers_count').alias('user_followers_count'),\n",
    "                                 F.col('user.friends_count').alias('user_friends_count'),\n",
    "                                 F.col('user.id').alias('user_id'),\n",
    "                                 F.col('user.location').alias('user_location'),\n",
    "                                 F.col('user.lang').alias('user_lang'), \n",
    "                                 F.col('user.verified').alias('user_verified')]).na.drop('all')\n",
    "#                                  F.col('coal_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_uni = tweets_uni.withColumn('is_quote', ~F.col('quoted_status').isNull()) \\\n",
    "                .withColumn('is_retweet', ~F.col('retweeted_status').isNull()) \\\n",
    "                .withColumn('is_reply', ~F.col('is_reply').isNull()) \\\n",
    "                .drop(F.col('quoted_status')).drop(F.col('retweeted_status')).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_uni = tweets_uni.withColumn('clean_text', F.regexp_replace(F.col('coal_text'),r'[^\\w\\s]',''))\n",
    "\n",
    "tweets_uni = tweets_uni.withColumn(\"clean_text\",F.regexp_replace(F.lower(F.col(\"clean_text\")), r\"[0-9]+\", \"\"))\n",
    "\n",
    "tweets_uni = tweets_uni.withColumn(\"clean_text\",F.regexp_replace(F.col(\"clean_text\"), r\"http\\S+\", \"\"))\n",
    "\n",
    "tweets_uni = tweets_uni.drop('coal_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_uni = tweets_uni.withColumn('media', ~F.col('media_type').isNull()).drop('media_type')\n",
    "tweets_uni = tweets_uni.withColumn('media', F.col('media').cast('integer'))\n",
    "tweets_uni = tweets_uni.withColumn('user_verified', F.col('user_verified').cast('integer'))\n",
    "tweets_uni = tweets_uni.withColumn('is_reply', F.col('is_reply').cast('integer'))\n",
    "tweets_uni = tweets_uni.withColumn('is_quote', F.col('is_quote').cast('integer'))\n",
    "tweets_uni = tweets_uni.withColumn('is_retweet', F.col('is_retweet').cast('integer'))\n",
    "tweets_uni = tweets_uni.withColumn('user_mentions', ~F.col('user_mentions_id').isNull()).drop('user_mentions_id')\n",
    "tweets_uni = tweets_uni.withColumn('user_mentions', F.col('user_mentions').cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_uni = tweets_uni.withColumn('is_reply', F.col('is_reply').cast('integer')) \\\n",
    "#         .withColumn('user_verified', F.col('user_verified').cast('integer')) \\\n",
    "#         .withColumn('is_quote', F.col('is_quote').cast('integer')) \\\n",
    "#         .withColumn('is_retweet', F.col('is_retweet').cast('integer')) \\\n",
    "#         .withColumn('media', F.col('media').cast('integer')) \\\n",
    "#         .withColumn('user_mentions', F.col('user_mentions').cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_id: long (nullable = true)\n",
      " |-- tweet_dt: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- school: string (nullable = true)\n",
      " |-- is_reply: integer (nullable = false)\n",
      " |-- favorite_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- user_created_at: string (nullable = true)\n",
      " |-- user_favorites_count: long (nullable = true)\n",
      " |-- user_followers_count: long (nullable = true)\n",
      " |-- user_friends_count: long (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- user_location: string (nullable = true)\n",
      " |-- user_lang: string (nullable = true)\n",
      " |-- user_verified: integer (nullable = true)\n",
      " |-- is_quote: integer (nullable = false)\n",
      " |-- is_retweet: integer (nullable = false)\n",
      " |-- media: integer (nullable = false)\n",
      " |-- user_mentions: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_uni.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract variables for local analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_uni.write.format('com.databricks.spark.csv').mode('overwrite').option('header','true').save('/user/jhuff1/project/tweet_variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -getmerge '/user/jhuff1/project/tweet_variables' '/home/jhuff1/tweet_variables.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0\n",
      "2021-03-11 23:34:50,501 INFO  [main] fs.TrashPolicyDefault (TrashPolicyDefault.java:moveToTrash(182)) - Moved: 'hdfs://nameservice1/user/jhuff1/project/tweet_variables' to trash at: hdfs://nameservice1/user/jhuff1/.Trash/Current/user/jhuff1/project/tweet_variables\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm -r '/user/jhuff1/project/tweet_variables'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
